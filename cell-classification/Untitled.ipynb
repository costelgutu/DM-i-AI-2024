{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2126981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 12:18:43.530662: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-02 12:18:43.562105: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-02 12:18:43.570019: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-02 12:18:43.629916: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-02 12:18:46.166347: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.client import device_lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baf77c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if TensorFlow is using a GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"TensorFlow is using the following GPU(s):\")\n",
    "    for gpu in gpus:\n",
    "        print(gpu)\n",
    "else:\n",
    "    print(\"No GPU detected for TensorFlow.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9762fd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d293cd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Create a random tensor\n",
    "matrix1 = tf.random.normal([10000, 10000])\n",
    "matrix2 = tf.random.normal([10000, 10000])\n",
    "\n",
    "# Perform matrix multiplication on the GPU\n",
    "start_time = time.time()\n",
    "result = tf.matmul(matrix1, matrix2)\n",
    "print(\"GPU computation time:\", time.time() - start_time)\n",
    "\n",
    "# Check if the operation was performed on the GPU\n",
    "print(\"GPU used:\", result.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33db1aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f56d165",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Allow TensorFlow to only use a limited amount of memory on the GPU\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5039c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all available devices\n",
    "devices = device_lib.list_local_devices()\n",
    "print(\"Available devices:\")\n",
    "for device in devices:\n",
    "    print(device.name, device.device_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e030d9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "data_dir = 'data/training'  # Folder with .tif images\n",
    "csv_file = 'data/training.csv'  # CSV file with image_id and is_homogeneous\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49accf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd3e76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c670fbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip any leading/trailing spaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Now you can access 'image_id' without the extra space\n",
    "image_id_values = df['image_id'].values\n",
    "print(image_id_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0434152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path):\n",
    "    # Load image with PIL and convert to an array\n",
    "    img = load_img(image_path, target_size=IMG_SIZE)\n",
    "    img_array = img_to_array(img)\n",
    "    # Normalize image pixel values (0-255 -> 0-1)\n",
    "    img_array = img_array / 255.0\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d455a42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8a1081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create lists of image paths and labels\n",
    "# Assuming image_id values need to be 3 digits with leading zeros\n",
    "image_paths = [os.path.join(data_dir, f\"{str(image_id).zfill(3)}.tif\") for image_id in df['image_id']]\n",
    "labels = df['is_homogenous'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1908ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ed7444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Load images and preprocess them\n",
    "images = np.array([load_and_preprocess_image(image_path) for image_path in image_paths])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398e0219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e985c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Create data generators for augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb492cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3eeea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Create the data generators\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496e41e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Load the pre-trained VGG16 model without the top layer\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4638ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fca8fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Create the model by adding custom layers on top of the pre-trained base model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),  # Add dropout for regularization\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43944513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c7dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,  # Adjust the number of epochs as needed\n",
    "    validation_data=val_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea145e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Evaluate the model on the validation set\n",
    "val_loss, val_acc = model.evaluate(val_generator)\n",
    "print(f\"Validation Accuracy: {val_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572566c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('vgg16_homogeneous_classification.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5899734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22b86c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model('vgg16_homogeneous_classification.h5')  # Path to your saved model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33474216",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_accuracy = model1.evaluate(X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af8ea51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Validation Loss: {val_loss}')\n",
    "print(f'Validation Accuracy: {val_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b089b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_val)\n",
    "predicted_labels = (predictions >= 0.5).astype(int)  # Threshold at 0.5 to get binary labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b4030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75069e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val, predicted_labels, target_names=['Heterogeneous', 'Homogeneous']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c781f14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming y_val contains the true labels and predicted_labels contains the predicted labels\n",
    "\n",
    "# Step 1: Calculate n_0 and n_1\n",
    "n_0 = np.sum(y_val == 0)  # Number of true heterogeneous cells\n",
    "n_1 = np.sum(y_val == 1)  # Number of true homogeneous cells\n",
    "\n",
    "# Step 2: Calculate a_0 and a_1\n",
    "a_0 = np.sum((y_val == 0) & (predicted_labels == 0))  # Correctly predicted as heterogeneous\n",
    "a_1 = np.sum((y_val == 1) & (predicted_labels == 1))  # Correctly predicted as homogeneous\n",
    "\n",
    "# Step 3: Calculate the score\n",
    "if n_0 == 0 or n_1 == 0:\n",
    "    score = 0  # Handle edge cases where there are no samples of a class\n",
    "else:\n",
    "    score = (a_0 * a_1) / (n_0 * n_1)\n",
    "\n",
    "print(f'Score: {score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a2fba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d5173c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558369f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cellclass)",
   "language": "python",
   "name": "cellclass"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
