{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2126981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.client import device_lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baf77c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if TensorFlow is using a GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"TensorFlow is using the following GPU(s):\")\n",
    "    for gpu in gpus:\n",
    "        print(gpu)\n",
    "else:\n",
    "    print(\"No GPU detected for TensorFlow.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9762fd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33db1aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e030d9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "data_dir = 'data/training'  # Folder with .tif images\n",
    "csv_file = 'data/training.csv'  # CSV file with image_id and is_homogeneous\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49accf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd3e76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c670fbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip any leading/trailing spaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Now you can access 'image_id' without the extra space\n",
    "image_id_values = df['image_id'].values\n",
    "print(image_id_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0434152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path):\n",
    "    # Load image with PIL and convert to an array\n",
    "    img = load_img(image_path, target_size=IMG_SIZE)\n",
    "    img_array = img_to_array(img)\n",
    "    # Normalize image pixel values (0-255 -> 0-1)\n",
    "    img_array = img_array / 255.0\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d455a42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8a1081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create lists of image paths and labels\n",
    "# Assuming image_id values need to be 3 digits with leading zeros\n",
    "image_paths = [os.path.join(data_dir, f\"{str(image_id).zfill(3)}.tif\") for image_id in df['image_id']]\n",
    "labels = df['is_homogenous'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ed7444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Load images and preprocess them\n",
    "images = np.array([load_and_preprocess_image(image_path) for image_path in image_paths])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398e0219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7648ed-c896-40ab-ba38-dae513d24960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming y_train is a NumPy array of labels\n",
    "# Separate majority and minority class samples\n",
    "X_train_majority = X_train[y_train == 0]  # Majority class (e.g., Heterogeneous)\n",
    "y_train_majority = y_train[y_train == 0]\n",
    "\n",
    "X_train_minority = X_train[y_train == 1]  # Minority class (e.g., Homogeneous)\n",
    "y_train_minority = y_train[y_train == 1]\n",
    "\n",
    "print(f\"Majority class samples: {len(y_train_majority)}\")\n",
    "print(f\"Minority class samples: {len(y_train_minority)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8c5ead-3864-4b53-a2a1-5d6b4c2100c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation parameters for the minority class\n",
    "minority_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd5fbeb-cdba-424d-9a38-0e88866331b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how many augmented images we need\n",
    "num_majority_samples = len(y_train_majority)\n",
    "num_minority_samples = len(y_train_minority)\n",
    "num_augmented_images_needed = num_majority_samples - num_minority_samples\n",
    "\n",
    "print(f\"Number of augmented images needed: {num_augmented_images_needed}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0328ae7-438e-4b32-8962-a902ddd52c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X_train_minority for the generator\n",
    "X_train_minority = X_train_minority.reshape((-1, IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "\n",
    "# Create a generator for the minority class\n",
    "minority_generator = minority_datagen.flow(\n",
    "    X_train_minority,\n",
    "    y_train_minority,\n",
    "    batch_size=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Generate augmented images\n",
    "X_augmented = []\n",
    "y_augmented = []\n",
    "\n",
    "for i in range(num_augmented_images_needed):\n",
    "    X_batch, y_batch = next(minority_generator)\n",
    "    X_augmented.append(X_batch[0])\n",
    "    y_augmented.append(y_batch[0])\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X_augmented = np.array(X_augmented)\n",
    "y_augmented = np.array(y_augmented)\n",
    "\n",
    "print(f\"Augmented images generated: {len(y_augmented)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ac5911-9ed0-4d21-af2a-fdb868b1dd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine original minority data with augmented data\n",
    "X_minority_balanced = np.concatenate([X_train_minority, X_augmented])\n",
    "y_minority_balanced = np.concatenate([y_train_minority, y_augmented])\n",
    "\n",
    "# Combine with majority class data\n",
    "X_train_balanced = np.concatenate([X_train_majority, X_minority_balanced])\n",
    "y_train_balanced = np.concatenate([y_train_majority, y_minority_balanced])\n",
    "\n",
    "print(f\"Balanced training samples: {len(y_train_balanced)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccd74d9-09bf-454e-946c-32bddc31d87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train_balanced, y_train_balanced = shuffle(X_train_balanced, y_train_balanced, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7e05eb-ce46-49bd-b180-99a94f90ab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator for the balanced dataset (minimal augmentation)\n",
    "train_datagen_balanced = ImageDataGenerator(\n",
    "    rescale=1./255  # Normalize pixel values\n",
    ")\n",
    "\n",
    "train_generator = train_datagen_balanced.flow(\n",
    "    X_train_balanced, y_train_balanced, batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Validation data generator (normalize)\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow(\n",
    "    X_val, y_val, batch_size=BATCH_SIZE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851e9537-18f5-4dfa-b9be-d00e534f4dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ba5a7a-1980-4ccb-8756-4b9d5da23115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020f37ef-2cc8-4257-8f70-33d058b6e6c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e985c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Create data generators for augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb492cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3eeea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Create the data generators\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496e41e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Load the pre-trained VGG16 model without the top layer\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4638ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fca8fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Create the model by adding custom layers on top of the pre-trained base model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),  # Add dropout for regularization\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43944513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c7dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=30,  # Adjust the number of epochs as needed\n",
    "    validation_data=val_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea145e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Evaluate the model on the validation set\n",
    "val_loss, val_acc = model.evaluate(val_generator)\n",
    "print(f\"Validation Accuracy: {val_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572566c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('vgg16_homogeneous_classification.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5899734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22b86c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model('vgg16_homogeneous_classification.h5')  # Path to your saved model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33474216",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_accuracy = model1.evaluate(X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af8ea51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Validation Loss: {val_loss}')\n",
    "print(f'Validation Accuracy: {val_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b089b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_val)\n",
    "predicted_labels = (predictions >= 0.5).astype(int)  # Threshold at 0.5 to get binary labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b4030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75069e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val, predicted_labels, target_names=['Heterogeneous', 'Homogeneous']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c781f14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming y_val contains the true labels and predicted_labels contains the predicted labels\n",
    "\n",
    "# Step 1: Calculate n_0 and n_1\n",
    "n_0 = np.sum(y_val == 0)  # Number of true heterogeneous cells\n",
    "n_1 = np.sum(y_val == 1)  # Number of true homogeneous cells\n",
    "\n",
    "# Step 2: Calculate a_0 and a_1\n",
    "a_0 = np.sum((y_val == 0) & (predicted_labels == 0))  # Correctly predicted as heterogeneous\n",
    "a_1 = np.sum((y_val == 1) & (predicted_labels == 1))  # Correctly predicted as homogeneous\n",
    "\n",
    "# Step 3: Calculate the score\n",
    "if n_0 == 0 or n_1 == 0:\n",
    "    score = 0  # Handle edge cases where there are no samples of a class\n",
    "else:\n",
    "    score = (a_0 * a_1) / (n_0 * n_1)\n",
    "\n",
    "print(f'Score: {score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a2fba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d5173c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558369f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cellclass)",
   "language": "python",
   "name": "cellclass"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
