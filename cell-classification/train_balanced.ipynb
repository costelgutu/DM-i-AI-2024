{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2126981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 13:14:19.732183: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-02 13:14:20.407449: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-02 13:14:20.484683: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-02 13:14:21.173323: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-02 13:14:24.156821: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.client import device_lib\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.utils import resample, shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7baf77c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow is using the following GPU(s):\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "# Check if TensorFlow is using a GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"TensorFlow is using the following GPU(s):\")\n",
    "    for gpu in gpus:\n",
    "        print(gpu)\n",
    "else:\n",
    "    print(\"No GPU detected for TensorFlow.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9762fd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33db1aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e030d9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "data_dir = 'data/training'  # Folder with .tif images\n",
    "csv_file = 'data/training.csv'  # CSV file with image_id and is_homogeneous\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c49accf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbd3e76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c670fbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[279 277 275 273 271 269 267 265 263 261 259 257 255 253 251 249 247 245\n",
      " 243 241 239 237 235 233 231 229 227 225 223 221 219 217 215 213 211 209\n",
      " 207 205 203 201 199 197 195 193 191 189 187 185 183 181 179 177 175 173\n",
      " 171 169 167 165 163 161 159 157 155 153 151 149 147 145 143 141 139 137\n",
      " 135 133 131 129 127 125 123 121 119 117 115 113 111 109 107 105 103 101\n",
      "  99  97  95  93  91  89  87  85  83  81  79  77  75  73  71  69  67  65\n",
      "  63  61  59  57  55  53  51  49  47  45  43  41  39  37  35  33  29  27\n",
      "  25  23  21  19  17  15  13  11   9   7   5   3   1]\n"
     ]
    }
   ],
   "source": [
    "# Strip any leading/trailing spaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Now you can access 'image_id' without the extra space\n",
    "image_id_values = df['image_id'].values\n",
    "print(image_id_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0434152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path):\n",
    "    # Load image with PIL and convert to an array\n",
    "    img = load_img(image_path, target_size=IMG_SIZE)\n",
    "    img_array = img_to_array(img)\n",
    "    # Normalize image pixel values (0-255 -> 0-1)\n",
    "    img_array = img_array / 255.0\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d455a42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image_id', 'is_homogenous'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d8a1081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create lists of image paths and labels\n",
    "# Assuming image_id values need to be 3 digits with leading zeros\n",
    "image_paths = [os.path.join(data_dir, f\"{str(image_id).zfill(3)}.tif\") for image_id in df['image_id']]\n",
    "labels = df['is_homogenous'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5ed7444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Load images and preprocess them\n",
    "images = np.array([load_and_preprocess_image(image_path) for image_path in image_paths])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "398e0219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a48771a-bb65-4e0b-97f8-a5ca7b197725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bbb6d82-fa89-4c84-b3ab-4412de8fce64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 0.6098901098901099, 1: 2.775}\n"
     ]
    }
   ],
   "source": [
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "print(f\"Class weights: {class_weights_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfc05666-6792-4c52-953e-01cc52519033",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_dict = {0: 1.0, 1: 2.0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13169cb3-ca09-4816-a9d5-f25ee174feef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514b468e-bf2c-4b86-b9a3-438c7a4d431b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47e985c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Create data generators for augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccb492cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e3eeea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Create the data generators\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "496e41e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 13:14:41.816707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38137 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:01:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "# 8. Load the pre-trained VGG16 model without the top layer\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4638ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fca8fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Create the model by adding custom layers on top of the pre-trained base model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),  # Add dropout for regularization\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43944513",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cogu/.conda/envs/cellclass/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/home/cogu/.conda/envs/cellclass/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.17.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa  # same as regular TensorFlow Addons\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss=tfa.losses.SigmoidFocalCrossEntropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c7dfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cogu/.conda/envs/cellclass/lib/python3.9/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727867686.558744   10951 service.cc:146] XLA service 0x7f9b7000c120 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1727867686.558785   10951 service.cc:154]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-10-02 13:14:46.626644: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-02 13:14:52.643003: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-10-02 13:14:53.863331: W external/local_xla/xla/service/gpu/nvptx_compiler.cc:762] The NVIDIA driver's CUDA version is 12.0 which is older than the ptxas CUDA version (12.3.107). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n",
      "I0000 00:00:1727867714.130567   10951 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/7\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 5s/step - accuracy: 0.5938 - loss: 2.0708  "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,  # Adjust the number of epochs as needed\n",
    "    validation_data=val_generator,\n",
    "    class_weight=class_weights_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea145e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Evaluate the model on the validation set\n",
    "val_loss, val_acc = model.evaluate(val_generator)\n",
    "print(f\"Validation Accuracy: {val_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572566c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('vgg16_homogeneous_classification.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5899734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22b86c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model('vgg16_homogeneous_classification.h5')  # Path to your saved model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33474216",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af8ea51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Validation Loss: {val_loss}')\n",
    "print(f'Validation Accuracy: {val_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b089b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_val)\n",
    "predicted_labels = (predictions >= 0.5).astype(int)  # Threshold at 0.5 to get binary labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b4030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75069e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val, predicted_labels, target_names=['Heterogeneous', 'Homogeneous']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c781f14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming y_val contains the true labels and predicted_labels contains the predicted labels\n",
    "\n",
    "# Step 1: Calculate n_0 and n_1\n",
    "n_0 = np.sum(y_val == 0)  # Number of true heterogeneous cells\n",
    "n_1 = np.sum(y_val == 1)  # Number of true homogeneous cells\n",
    "\n",
    "# Step 2: Calculate a_0 and a_1\n",
    "a_0 = np.sum((y_val == 0) & (predicted_labels == 0))  # Correctly predicted as heterogeneous\n",
    "a_1 = np.sum((y_val == 1) & (predicted_labels == 1))  # Correctly predicted as homogeneous\n",
    "\n",
    "# Step 3: Calculate the score\n",
    "if n_0 == 0 or n_1 == 0:\n",
    "    score = 0  # Handle edge cases where there are no samples of a class\n",
    "else:\n",
    "    score = (a_0 * a_1) / (n_0 * n_1)\n",
    "\n",
    "print(f'Score: {score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a2fba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d5173c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558369f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cellclass)",
   "language": "python",
   "name": "cellclass"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
